# 1. OneDrive获取API

1. 点击应用注册

注意：即使已经注册了Microsoft账户，如`hotmail`和`outlook`邮箱，仍需要新注册Azure，包括绑定真实IP所在地区的手机号，否则即使登陆了Azure也无法获得所有权限。另外，对于非学生用户，Azure需要绑定信用卡。

登录[azure](https://azure.microsoft.com/zh-cn/)，点击`所有服务`，在`标识`分类中找到`应用注册`

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240116-165811.png" alt="Image Description" width="700">
</p>


2. 点击新注册

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240116-171113.png" alt="Image Description" width="700">
</p>


- 如果出现以下提示，表明：2024年6月份以前是可以使用 Microsoft 个人账户注册应用程序。

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240504-191100.png" alt="Image Description" width="700">
</p>

其实只要注册一个Azure账号，获取应用程序ID和密匙，使用rclone上传文件到多个 onedrive 账户时是可以共用这一个 应用程序ID 和 密匙 的，不需要注册多个azure账号（注册azure账号需要绑定visa信用卡）。

3. 注册应用程序

填写名称，选择账户类型以及重定向URL，参考图中参数进行设置

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240116-171551.png" alt="Image Description" width="700">
</p>


4. 获取应用程序ID

创建成功后，复制并保存好应用程序ID，注意此处的ID为**客户端ID**，后续配置rclone时会用到

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240116-171926.png" alt="Image Description" width="700">
</p>


5. 点击证书和密码，添加**客户端密码**（有效期24个月）

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240116-173242.png" alt="Image Description" width="700">
</p>


6. 复制保存客户端密码

注意此处的值对应**客户端密码**，后续配置rclone时会用到

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240116-173545.png" alt="Image Description" width="700">
</p>

7. 设置API权限

先点击`API权限`，再点击`添加权限`，最后点击 `Microsoft Graph`

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240116-174848.png" alt="Image Description" width="700">
</p>

选择`委托的权限`

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240116-175108.png" alt="Image Description" width="700">
</p>

选择相应权限，可在搜索栏中快速检索权限

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240116-175734.png" alt="Image Description" width="700">
</p>

添加如下所示的6个权限

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240116-175603.png" alt="Image Description" width="700">
</p>


### 参考资料

1. OneDrive API 申请：https://kkxz.xyz/index.php/archives/83.html
2. Onedrive云存储自建API：https://blog.csdn.net/Roger_Spencer/article/details/134001696



# 2. 在本地获取rclone token

## 1. 在本地获取rclone用于onedrive账户验证token


### 1. 下载rclone

网址：https://rclone.org/downloads/

选择windows版本的的压缩包`rclone-v1.65.1-windows-amd64.zip`



### 2. 解压缩并授权账户

- 对rclone压缩包进行解压缩，进入到解压缩后的文件夹中，打开cmd窗口，运行如下命令

```sh
rclone authorize "onedrive" "Client_ID" "Client_secret"
```

将`"Client_ID" "Client_secret"`替换为上述申请OneDrive API时获取的`客户端ID和密码`


- 注意：上述直接获取 OneDrive token 的方式可能已不再适用，edge获取token时可能会出现如下报错：

```
NOTICE: Make sure your Redirect URL is set to "http://localhost:53682/" in your custom config.
Error: config failed to refresh token: failed to start auth webserver: listen tcp 127.0.0.1:53682: bind: An attempt was made to access a socket in a way forbidden by its access permissions.
```

- 如果遇到报错，参考 `rclone config` 认证过程出现的以下提示，需使用如下 `rclone authorize` 命令进行edge认证**

```sh
Execute the following on the machine with the web browser (same rclone version recommended):
	rclone authorize "onedrive" "eyJjbGllbnRfaWQiOiI4YWNhNzkzYy1hOD**********ljRDM4eTVPMnZfdGx3V3VQdXlidmR6bSJ9"
Then paste the result.
```

推荐浏览器获取token的 rclone 版本与服务器上认证的 rclone 版本一致。


### 3. 切换微软帐户

运行上述命令后会在默认浏览器中打开如下窗口进行确认，注意核对邮箱账户。

- 通常来说会使用**Edge浏览器**打开如下窗口，并使用**Edge已登录的 Microsoft 账户**进行授权，所以可以通过登录多个不同 Microsoft 账户来使用同一个应用程序 ID 和密码。

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240117-161603.png" alt="Image Description" width="350">
</p>

- 点击而接受后会返回如下success的提示，并在cmd窗口中返回token，该token之后会被用于云服务器上rclone对于onedrive账号的验证

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240117-161757.png" alt="Image Description" width="500">
</p>



### 4. cmd窗口返回token

成功后返回的字符串如下，复制`{xxxxxxxxx}`之间的部分

```
Paste the following into your remote machine --->
{"access_token":"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx","expiry":"2024-01-17T17:17:36.4788128+08:00"}
<---End paste
```

使用服务器 `rclone config` 认证过程出现的 `rclone authorize` 命令，获取的 token 格式与上述格式有明显不同




## 2. 多个 onedrive 账户共用相同`应用程序ID`和`密码`

你可以通过单个 Azure 应用程序 ID 和密码来管理多个 OneDrive 账户。你不需要为每个 OneDrive 账户创建单独的 Azure 应用程序。操作流程如下：

1. 应用程序注册：确保你在 Azure 中已经注册了应用程序，并获得了应用程序 ID（客户端 ID）和密码（客户端密钥）。
2. 配置权限：为该应用程序配置所需的 API 权限，确保它能够访问每个 OneDrive 账户的必要权限。通常是 Files.ReadWrite 或 Files.ReadWrite.All 权限。
3. 授权用户：使用 rclone 或其他 OAuth 客户端工具，你可以逐一为每个 OneDrive 账户完成 OAuth 认证过程。这样，每个账户都将获得一个关联的访问令牌和刷新令牌。
4. 多账户管理：在 rclone 中，你可以为每个 OneDrive 账户配置单独的远程（remote），并使用相同的 Azure 应用程序 ID 和密码完成每个账户的认证过程。这将允许你通过相同的应用程序凭证来访问和管理不同的账户。


## 3.  Microsoft 账户查看已授权的应用程序和服务

在 Microsoft 账户中，你可以管理已授权的应用程序和服务。这里是如何查看和管理这些授权：

1. 登录 Microsoft 账户：
- 使用你的 Microsoft 账户登录 Microsoft 账户管理页面，通常可通过 [account.microsoft.com](https://account.microsoft.com/) 访问。

2. 导航到“隐私”选项卡：
- 登录成功后，点击顶部导航栏中的“隐私”选项卡，或直接访问“隐私”页面。

3. 查看和管理应用权限：
- 在“隐私”页面的左侧菜单中，选择“应用和服务”。
- 这将列出你已授权访问 Microsoft 账户信息的应用和服务。
- 你可以查看每个应用程序的详细信息，包括它们的权限，并选择“移除”取消对特定应用程序的授权。

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240504-185709.png" alt="Image Description" width="700">
</p>

4. 定期检查：
- 建议定期检查这个列表，以确保只保留可信应用和服务的权限。如果发现不再使用的应用或可疑授权，及时移除它们。

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240504-185540.png" alt="Image Description" width="700">
</p>



# 3. 云服务器安装rclone

### 1. 脚本安装

Linux/macOS/BSD系统上安装rclone的脚本如下，查看[官方安装教程](https://rclone.org/install/)

```
sudo -v ; curl https://rclone.org/install.sh | sudo bash
```
安装成功后会有如下提示

```
rclone v1.65.1 has successfully installed.
Now run "rclone config" for setup. Check https://rclone.org/docs/ for more details.
```

注意：上述安装脚本支持版本更新。如果低版本的rclone在复制或者同步远程文件到本地时出现问题，可以使用上述命令更新到最新版本。经测试，更新版本能解决复制和同步授权的问题。


### 2. 预编译二进制文件手动安装

[官方安装教程](https://rclone.org/install/#linux)

1. 下载及解压缩安装包

```sh
curl -O https://downloads.rclone.org/rclone-current-linux-amd64.zip
unzip rclone-current-linux-amd64.zip
cd rclone-*-linux-amd64
```

2. 复制二进制文件到云服务器中存放可执行二进制文件的标准目录，并设置权限和组

```sh
sudo cp rclone /usr/bin/
sudo chown root:root /usr/bin/rclone
sudo chmod 755 /usr/bin/rclone
```

3. 安装 manpage

"Manpage" 是 "manual page" 的缩写，指的是在Unix和类Unix系统上用于提供命令、函数、系统调用等文档的页面。这些页面包含有关特定命令或程序如何使用的详细信息。

```sh
sudo mkdir -p /usr/local/share/man/man1
sudo cp rclone.1 /usr/local/share/man/man1/
sudo mandb
```

4. 启动

```sh
rclone config
```


### 3. 手动版本更新

1. 在线安装脚本 [install.sh](https://rclone.org/install.sh)

```sh
#!/usr/bin/env bash

# error codes
# 0 - exited without problems
# 1 - parameters not supported were used or some unexpected error occurred
# 2 - OS not supported by this script
# 3 - installed version of rclone is up to date
# 4 - supported unzip tools are not available

set -e

#when adding a tool to the list make sure to also add its corresponding command further in the script
unzip_tools_list=('unzip' '7z' 'busybox')

usage() { echo "Usage: sudo -v ; curl https://rclone.org/install.sh | sudo bash [-s beta]" 1>&2; exit 1; }

#check for beta flag
if [ -n "$1" ] && [ "$1" != "beta" ]; then
    usage
fi

if [ -n "$1" ]; then
    install_beta="beta "
fi


#create tmp directory and move to it with macOS compatibility fallback
tmp_dir=$(mktemp -d 2>/dev/null || mktemp -d -t 'rclone-install.XXXXXXXXXX')
cd "$tmp_dir"


#make sure unzip tool is available and choose one to work with
set +e
for tool in ${unzip_tools_list[*]}; do
    trash=$(hash "$tool" 2>>errors)
    if [ "$?" -eq 0 ]; then
        unzip_tool="$tool"
        break
    fi
done  
set -e

# exit if no unzip tools available
if [ -z "$unzip_tool" ]; then
    printf "\nNone of the supported tools for extracting zip archives (${unzip_tools_list[*]}) were found. "
    printf "Please install one of them and try again.\n\n"
    exit 4
fi

# Make sure we don't create a root owned .config/rclone directory #2127
export XDG_CONFIG_HOME=config

#check installed version of rclone to determine if update is necessary
version=$(rclone --version 2>>errors | head -n 1)
if [ -z "$install_beta" ]; then
    current_version=$(curl -fsS https://downloads.rclone.org/version.txt)
else
    current_version=$(curl -fsS https://beta.rclone.org/version.txt)
fi

if [ "$version" = "$current_version" ]; then
    printf "\nThe latest ${install_beta}version of rclone ${version} is already installed.\n\n"
    exit 3
fi


#detect the platform
OS="$(uname)"
case $OS in
  Linux)
    OS='linux'
    ;;
  FreeBSD)
    OS='freebsd'
    ;;
  NetBSD)
    OS='netbsd'
    ;;
  OpenBSD)
    OS='openbsd'
    ;;  
  Darwin)
    OS='osx'
    binTgtDir=/usr/local/bin
    man1TgtDir=/usr/local/share/man/man1
    ;;
  SunOS)
    OS='solaris'
    echo 'OS not supported'
    exit 2
    ;;
  *)
    echo 'OS not supported'
    exit 2
    ;;
esac

OS_type="$(uname -m)"
case "$OS_type" in
  x86_64|amd64)
    OS_type='amd64'
    ;;
  i?86|x86)
    OS_type='386'
    ;;
  aarch64|arm64)
    OS_type='arm64'
    ;;
  armv7*)
    OS_type='arm-v7'
    ;;
  armv6*)
    OS_type='arm-v6'
    ;;
  arm*)
    OS_type='arm'
    ;;
  *)
    echo 'OS type not supported'
    exit 2
    ;;
esac


#download and unzip
if [ -z "$install_beta" ]; then
    download_link="https://downloads.rclone.org/rclone-current-${OS}-${OS_type}.zip"
    rclone_zip="rclone-current-${OS}-${OS_type}.zip"
else
    download_link="https://beta.rclone.org/rclone-beta-latest-${OS}-${OS_type}.zip"
    rclone_zip="rclone-beta-latest-${OS}-${OS_type}.zip"
fi

curl -OfsS "$download_link"
unzip_dir="tmp_unzip_dir_for_rclone"
# there should be an entry in this switch for each element of unzip_tools_list
case "$unzip_tool" in
  'unzip')
    unzip -a "$rclone_zip" -d "$unzip_dir"
    ;;
  '7z')
    7z x "$rclone_zip" "-o$unzip_dir"
    ;;
  'busybox')
    mkdir -p "$unzip_dir"
    busybox unzip "$rclone_zip" -d "$unzip_dir"
    ;;
esac

cd $unzip_dir/*

#mounting rclone to environment

case "$OS" in
  'linux')
    #binary
    cp rclone /usr/bin/rclone.new
    chmod 755 /usr/bin/rclone.new
    chown root:root /usr/bin/rclone.new
    mv /usr/bin/rclone.new /usr/bin/rclone
    #manual
    if ! [ -x "$(command -v mandb)" ]; then
        echo 'mandb not found. The rclone man docs will not be installed.'
    else 
        mkdir -p /usr/local/share/man/man1
        cp rclone.1 /usr/local/share/man/man1/
        mandb
    fi
    ;;
  'freebsd'|'openbsd'|'netbsd')
    #binary
    cp rclone /usr/bin/rclone.new
    chown root:wheel /usr/bin/rclone.new
    mv /usr/bin/rclone.new /usr/bin/rclone
    #manual
    mkdir -p /usr/local/man/man1
    cp rclone.1 /usr/local/man/man1/
    makewhatis
    ;;
  'osx')
    #binary
    mkdir -m 0555 -p ${binTgtDir}
    cp rclone ${binTgtDir}/rclone.new
    mv ${binTgtDir}/rclone.new ${binTgtDir}/rclone
    chmod a=x ${binTgtDir}/rclone
    #manual
    mkdir -m 0555 -p ${man1TgtDir}
    cp rclone.1 ${man1TgtDir}    
    chmod a=r ${man1TgtDir}/rclone.1
    ;;
  *)
    echo 'OS not supported'
    exit 2
esac

#update version variable post install
version=$(rclone --version 2>>errors | head -n 1)

#cleanup
rm -rf "$tmp_dir"

printf "\n${version} has successfully installed."
printf '\nNow run "rclone config" for setup. Check https://rclone.org/docs/ for more details.\n\n'
exit 0
```

- 上述脚本中关于版本更新的部分

<p align="center">
<img src="https://19640810.xyz/05_image/01_imageHost/20240921-215033.png" alt="Image Description" width="700">
</p>



2. 手动版本更新脚本参考 [update_rclone.sh](/888/8-001/update_rclone.sh)

- 下载最新版本的安装包
  - 操作系统`（${OS}）：Linux`
  - 系统架构`（${OS_type}）：x86_64`
  - 最新版本的rclone: https://downloads.rclone.org/version.txt
  - 下载链接：https://downloads.rclone.org/rclone-current-linux-amd64.zip


- 该脚本环境变量如下

```sh
# 在脚本中指定最新版本安装包的路径
ZIP_PATH="/home/00_software/rclone_v1.68.0/rclone-current-linux-amd64.zip"
```




# 4. 云服务器配置rclone

### 1. 云服务器配置rclone

1. 输入如下命令进行rclone配置

```
rclone config
```

```
(base) root@ubuntu-s-1vcpu-1gb-sgp1-01:/home/00_software/rclone# rclone confi
2024/01/17 17:14:56 NOTICE: Config file "/root/.config/rclone/rclone.conf" no
No remotes found, make a new one?
n) New remote
s) Set configuration password
q) Quit config
n/s/q> n
```

2. `n/s/q> `选择`n`，新建一个远程连接，下面提示输入自定义远程连接的名字`do1-1`

```
Enter name for new remote.
name> do1-1
```

3. 然后会列出多种云存储服务，输入`Microsoft OneDrive`对应的序号 34 即可

```
Option Storage.
Type of storage to configure.
Choose a number from below, or type in your own value.
 1 / 1Fichier
   \ (fichier)
 2 / Akamai NetStorage
   \ (netstorage)
 3 / Alias for an existing remote
   \ (alias)
 4 / Amazon Drive
   \ (amazon cloud drive)
 5 / Amazon S3 Compliant Storage Providers including AWS, Alibaba, ArvanCloud, Ceph, ChinaMobile, Cloudflare, DigitalOcean, Dreamhost, GCS, HuaweiOBS, IBMCOS, IDrive, IONOS, LyveCloud, Leviia, Liara, Linode, Minio, Netease, Petabox, RackCorp, Rclone, Scaleway, SeaweedFS, StackPath, Storj, Synology, TencentCOS, Wasabi, Qiniu and others
   \ (s3)
 6 / Backblaze B2
   \ (b2)
 7 / Better checksums for other remotes
   \ (hasher)
 8 / Box
   \ (box)
 9 / Cache a remote
   \ (cache)
10 / Citrix Sharefile
   \ (sharefile)
11 / Combine several remotes into one
   \ (combine)
12 / Compress a remote
   \ (compress)
13 / Dropbox
   \ (dropbox)
14 / Encrypt/Decrypt a remote
   \ (crypt)
15 / Enterprise File Fabric
   \ (filefabric)
16 / FTP
   \ (ftp)
17 / Google Cloud Storage (this is not Google Drive)
   \ (google cloud storage)
18 / Google Drive
   \ (drive)
19 / Google Photos
   \ (google photos)
20 / HTTP
   \ (http)
21 / Hadoop distributed file system
   \ (hdfs)
22 / HiDrive
   \ (hidrive)
23 / ImageKit.io
   \ (imagekit)
24 / In memory object storage system.
   \ (memory)
25 / Internet Archive
   \ (internetarchive)
26 / Jottacloud
   \ (jottacloud)
27 / Koofr, Digi Storage and other Koofr-compatible storage providers
   \ (koofr)
28 / Linkbox
   \ (linkbox)
29 / Local Disk
   \ (local)
30 / Mail.ru Cloud
   \ (mailru)
31 / Mega
   \ (mega)
32 / Microsoft Azure Blob Storage
   \ (azureblob)
33 / Microsoft Azure Files
   \ (azurefiles)
34 / Microsoft OneDrive
   \ (onedrive)
35 / OpenDrive
   \ (opendrive)
36 / OpenStack Swift (Rackspace Cloud Files, Blomp Cloud Storage, Memset Memstore, OVH)
   \ (swift)
37 / Oracle Cloud Infrastructure Object Storage
   \ (oracleobjectstorage)
38 / Pcloud
   \ (pcloud)
39 / PikPak
   \ (pikpak)
40 / Proton Drive
   \ (protondrive)
41 / Put.io
   \ (putio)
42 / QingCloud Object Storage
   \ (qingstor)
43 / Quatrix by Maytech
   \ (quatrix)
44 / SMB / CIFS
   \ (smb)
45 / SSH/SFTP
   \ (sftp)
46 / Sia Decentralized Cloud
   \ (sia)
47 / Storj Decentralized Cloud Storage
   \ (storj)
48 / Sugarsync
   \ (sugarsync)
49 / Transparently chunk/split large files
   \ (chunker)
50 / Union merges the contents of several upstream fs
   \ (union)
51 / Uptobox
   \ (uptobox)
52 / WebDAV
   \ (webdav)
53 / Yandex Disk
   \ (yandex)
54 / Zoho
   \ (zoho)
55 / premiumize.me
   \ (premiumizeme)
56 / seafile
   \ (seafile)
```

4. 接下来提示输入`客户端ID`和`客户端密码`，将onedrive api申请时获取的client_id和client_secret输入即可

```
Option client_id.
OAuth Client Id.
Leave blank normally.
Enter a value. Press Enter to leave empty.
client_id> 8acxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

Option client_secret.
OAuth Client Secret.
Leave blank normally.
Enter a value. Press Enter to leave empty.
client_secret> 69xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

5. 提示选择onedrive云服务的区域，选择`Microsoft Cloud Global`对应的序号1即可

```
Option region.
Choose national cloud region for OneDrive.
Choose a number from below, or type in your own string value.
Press Enter for the default (global).
 1 / Microsoft Cloud Global
   \ (global)
 2 / Microsoft Cloud for US Government
   \ (us)
 3 / Microsoft Cloud Germany
   \ (de)
 4 / Azure and Office 365 operated by Vnet Group in China
   \ (cn)
region> 1
```

- 注意：对于新版本的rclone，可能还会出现以下提示，直接 Enter 跳过即可。
  - 如果你使用的是企业版 OneDrive 或 OneDrive for Business，通常会涉及到 Azure AD 的设置。在这种环境下，你的应用可能需要使用 Client Credential Flow 来以应用身份进行认证，此时需要填写租户 ID。
  - 如果你是用个人版 OneDrive（或采用交互式授权，不是通过 Client Credential Flow）进行认证，一般情况下可以直接回车跳过此项，留空即可。

```
Option tenant.
ID of the service principal's tenant. Also called its directory ID.
Set this if using
- Client Credential flow
Enter a value. Press Enter to leave empty.
tenant>
```


6. 提示是否需要进行高级配置，选择 n 对应的 No 即可

```
Edit advanced config?
y) Yes
n) No (default)
y/n> n
```

7. 提示是否要用web浏览器进行rclone对远程连接的验证？由于是在ubuntu云服务器上操作，选择 n 即可，后续可以通过token进行验证

```
Use web browser to automatically authenticate rclone with remote?
 * Say Y if the machine running rclone has a web browser you can use
 * Say N if running rclone on a (remote) machine without web browser access
If not sure try Y. If Y failed, try N.

y) Yes (default)
n) No
y/n> n
```

8. 提示输入token进行验证，将之前获取的`{"xxxxxxxxxxxxxxxxxxxxxx"}`token输入即可（token放在了`D:\onedrive\英语\06_key_token`目录下）

```
Option config_token.
For this to work, you will need rclone available on a machine that has
a web browser available.
For more help and alternate methods see: https://rclone.org/remote_setup/
Execute the following on the machine with the web browser (same rclone
version recommended):
	rclone authorize "onedrive" "eyJjbGllbnRfaWQiOiI4YWNhNzkzYy1hODRiLTQ5NWYtYmI3Yi1jN2Nm**************ZHljRDM4eTVPMnZfdGx3V3VQdXlidmR6bSJ9"
Then paste the result.
Enter a value.
config_token> {"access_token":"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx","expiry":"2024-01-17T17:17:36.4788128+08:00"}
```

9. 选择验证类型，结合自身情况，选择` 1 / OneDrive Personal or Business`即可

```
Option config_type.
Type of connection
Choose a number from below, or type in an existing string value.
Press Enter for the default (onedrive).
 1 / OneDrive Personal or Business
   \ (onedrive)
 2 / Root Sharepoint site
   \ (sharepoint)
   / Sharepoint site name or URL
 3 | E.g. mysite or https://contoso.sharepoint.com/sites/mysite
   \ (url)
 4 / Search for a Sharepoint site
   \ (search)
 5 / Type in driveID (advanced)
   \ (driveid)
 6 / Type in SiteID (advanced)
   \ (siteid)
   / Sharepoint server-relative path (advanced)
 7 | E.g. /teams/hr
   \ (path)
config_type> 1
```


10. 接着需要进一步选择核对自己的onedrive账户

```
Option config_driveid.
Select drive you want to use
Choose a number from below, or type in your own string value.
Press Enter for the default (afd2dca4aabf9e92).
 1 /  (personal)
   \ (afd2dca4aabf9e92)
config_driveid> 1

Drive OK?

Found drive "root" of type "personal"
URL: https://onedrive.live.com/?cid=xxxxxxxxxxxxxxxxx

y) Yes (default)
n) No
y/n> y
```

注意：新版本的rclone认证过程可能会出现以下提示

```
Option config_driveid.
Select drive you want to use
Choose a number from below, or type in your own value of type string.
Press Enter for the default (AFD2DCA4AABF9E92).
 1 / Bundles_b896e2bb7ca3447691823a44c4ad6ad7 (personal)
   \ (AFD2DCA4AABF9E92)
 2 / AEEE102E-CFF8-4E2A-89C6-03841FF83500 (personal)
   \ (b!0u_QUGz-bki8OpItIAk0YfBBEaNTUCVMgIupHOUiIQqE53zBJe2VQK7heGOT3L7G)
 3 / OneDrive (personal)
   \ (AFD2DCA4AABF9E92)
 4 / ODCMetadataArchive (personal)
   \ (b!0u_QUGz-bki8OpItIAk0YfBBEaNTUCVMgIupHOUiIQqsqZIpRNwHSK9j-XY5y_OA)
config_driveid> 3

Drive OK?

Found drive "root" of type "personal"
URL: https://onedrive.live.com?cid=AFD2DCA4AABF************354PWSELRRZ

y) Yes (default)
n) No
y/n> y
```


11. 最后会显示输入的客户端ID，密码和token，进行最后的确认

```
Configuration complete.
Options:
- type: onedrive
- client_id: 8xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
- client_secret: 69xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
- token: {"access_token":"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx","expiry":"2024-01-17T18:24:42.074970193+08:00"}
- drive_id: axxxxxxxxxxxxx
- drive_type: personal
Keep this "do1-1" remote?
y) Yes this is OK (default)
e) Edit this remote
d) Delete this remote
y/e/d> y
```

12. 输入 y 创建远程连接，显示如下，输入 q 可以退出配置

```
Current remotes:

Name                 Type
====                 ====
do1-1                onedrive

e) Edit existing remote
n) New remote
d) Delete remote
r) Rename remote
c) Copy remote
s) Set configuration password
q) Quit config
e/n/d/r/c/s/q> q
```


### 2. 上传和下载测试

1. 上传测试，替换`do1-1`为上述创建的远程name，提前在onedrive上创建好`01_test/`目录

在本地创建一个文本文件，然后通过 rclone 工具将该文件复制到远程位置的指定目录下。

```sh
echo "Hello, this is a test file" > test.txt && rclone copy test.txt do1-1:01_test/
```

其中：

- `echo "Hello, this is a test file" > test.txt`: 创建一个名为 "test.txt" 的文本文件，并将字符串 "Hello, this is a test file" 写入该文件。
	
- `rclone copy test.txt do1-1:01_test/`: 使用 rclone 工具将本地的 "test.txt" 文件复制到远程位置 "do1-1" 下的 "01_test" 目录中。


2. 下载测试

将远程位置 `"do1-1:01_test/test.txt"` 下载到当前目录下

```sh
rclone copy do1-1:01_test/test.txt ./
```

- 在 `rclone copy` 命令中，如果远程目录下已经存在相同名称的文件，并且本地文件比远程文件更新（即修改时间更新或文件内容不同），那么远程文件将会被覆盖。否则，如果远程文件已经存在且未改变，文件不会被重新上传。

将远程目录下的文件复制到本地指定目录下，忽略本地已经存在的文件

```sh
rclone copy --ignore-existing HW-1012:do1-2/01_html/02_douyVideo /home/01_html/01_tecent1017/25_film_videos
```

3. 查看远程目录结构

```sh
rclone ls do1-1:
```

rclone 提供了 `rclone tree` 命令，你可以使用这个命令来显示远程目录的树状结构。要查看深度为2的目录，可以使用以下命令：

```sh
rclone tree do1-1: --max-depth 2
```

列出远程位置下的所有文件夹

```sh
rclone lsd remote_name:path/to/directory

rclone lsd rc4:/
```


4. 远程复制

使用 rclone 将本地 `/home/01_html/05_image` 目录下的所有文件复制到 `cc1-1` 远程位置下的 `cc1-1/05_image` 目录下

```sh
rclone copy /home/01_html/05_image cc1-1:cc1-1/05_image
rclone copy /home/01_html/09_VOALearningEnglish do1-1:do1-1/09_VOALearningEnglish
```

在 rclone 中，冒号（:）用于指示远程名称和路径的分隔。


5. 复制可选参数

- 不覆盖已存在的目标文件:

```sh
rclone copy --ignore-existing /home/01_html/05_image cc1-1:cc1-1/05_image
```

- 仅在源文件的修改时间比目标文件新时才复制:

```sh
rclone copy --update /home/01_html/05_image cc1-1:cc1-1/05_image
```


6. 使用rclone查看远程路径下的文件数量和大小

```sh
rclone size  do1-1:do1-1/42_TheDaily/01_audio
```


7. 验证服务器是否能够访问Microsoft Graph API

```sh
curl -v https://graph.microsoft.com/v1.0/
```


8. 创建远程目录

```sh
rclone mkdir do1-1:do1-1/49_CoffeeBreakEnglish
```

9. 查看所有远程账号

```sh
rclone listremotes
```

10. 查看系统中当前正在运行的所有`rclone`进程

```sh
ps aux | grep rclone
```

11. 实现后台指定数量文件的同时上传

```sh
nohup rclone copy /home/01_html/51_SEND7 cc1-1:cc1-1/51_SEND7 --transfers=16 &
```

12. 显示远程云盘的总空间、已用空间和剩余空间

```sh
rclone about rc4:
```

13. 后台复制指定目录到远程盘，`-P` 显示进度条（包括传输速度、剩余时间等信息），`> nohup.out 2>&1` 把标准输出和错误输出都重定向到文件 `nohup.out`

```sh
nohup rclone copy /home/01_html rc4:cloudServer_backup/ucld-0407/01_html -P > nohup.out 2>&1 &
```



### 3. `cp`命令行参数

```
cp --help

Usage: cp [OPTION]... [-T] SOURCE DEST
  or:  cp [OPTION]... SOURCE... DIRECTORY
  or:  cp [OPTION]... -t DIRECTORY SOURCE...
Copy SOURCE to DEST, or multiple SOURCE(s) to DIRECTORY.

Mandatory arguments to long options are mandatory for short options too.
  -a, --archive                same as -dR --preserve=all
      --attributes-only        don't copy the file data, just the attributes
      --backup[=CONTROL]       make a backup of each existing destination file
  -b                           like --backup but does not accept an argument
      --copy-contents          copy contents of special files when recursive
  -d                           same as --no-dereference --preserve=links
  -f, --force                  if an existing destination file cannot be
                                 opened, remove it and try again (this option
                                 is ignored when the -n option is also used)
  -i, --interactive            prompt before overwrite (overrides a previous -n
                                  option)
  -H                           follow command-line symbolic links in SOURCE
  -l, --link                   hard link files instead of copying
  -L, --dereference            always follow symbolic links in SOURCE
  -n, --no-clobber             do not overwrite an existing file (overrides
                                 a previous -i option)
  -P, --no-dereference         never follow symbolic links in SOURCE
  -p                           same as --preserve=mode,ownership,timestamps
      --preserve[=ATTR_LIST]   preserve the specified attributes (default:
                                 mode,ownership,timestamps), if possible
                                 additional attributes: context, links, xattr,
                                 all
      --no-preserve=ATTR_LIST  don't preserve the specified attributes
      --parents                use full source file name under DIRECTORY
  -R, -r, --recursive          copy directories recursively
      --reflink[=WHEN]         control clone/CoW copies. See below
      --remove-destination     remove each existing destination file before
                                 attempting to open it (contrast with --force)
      --sparse=WHEN            control creation of sparse files. See below
      --strip-trailing-slashes  remove any trailing slashes from each SOURCE
                                 argument
  -s, --symbolic-link          make symbolic links instead of copying
  -S, --suffix=SUFFIX          override the usual backup suffix
  -t, --target-directory=DIRECTORY  copy all SOURCE arguments into DIRECTORY
  -T, --no-target-directory    treat DEST as a normal file
  -u, --update                 copy only when the SOURCE file is newer
                                 than the destination file or when the
                                 destination file is missing
  -v, --verbose                explain what is being done
  -x, --one-file-system        stay on this file system
  -Z                           set SELinux security context of destination
                                 file to default type
      --context[=CTX]          like -Z, or if CTX is specified then set the
                                 SELinux or SMACK security context to CTX
      --help     display this help and exit
      --version  output version information and exit
```

### 4. rclone命令可选参数

- 参看可选参数命令

```
rclone help flags
```

- 所有可选参数


1. `copy`复制相关参数

```
Usage:
  rclone help flags [<regexp to match>] [flags]

Flags:
  -h, --help   help for flags


# Copy Flags

Flags for anything which can Copy a file.

      --check-first                                 Do all the checks before starting transfers
  -c, --checksum                                    Check for changes with size & checksum (if available, or fallback to size only).
      --compare-dest stringArray                    Include additional comma separated server-side paths during comparison
      --copy-dest stringArray                       Implies --compare-dest but also copies files from paths into destination
      --cutoff-mode HARD|SOFT|CAUTIOUS              Mode to stop transfers when reaching the max transfer limit HARD|SOFT|CAUTIOUS (default HARD)
      --ignore-case-sync                            Ignore case when synchronizing
      --ignore-checksum                             Skip post copy check of checksums
      --ignore-existing                             Skip all files that exist on destination
      --ignore-size                                 Ignore size when skipping use modtime or checksum
  -I, --ignore-times                                Don't skip files that match size and time - transfer all files
      --immutable                                   Do not modify files, fail if existing files have been modified
      --inplace                                     Download directly to destination file instead of atomic download to temp/rename
      --max-backlog int                             Maximum number of objects in sync or check backlog (default 10000)
      --max-duration Duration                       Maximum duration rclone will transfer data for (default 0s)
      --max-transfer SizeSuffix                     Maximum size of data to transfer (default off)
  -M, --metadata                                    If set, preserve metadata when copying objects
      --modify-window Duration                      Max time diff to be considered the same (default 1ns)
      --multi-thread-chunk-size SizeSuffix          Chunk size for multi-thread downloads / uploads, if not set by filesystem (default 64Mi)
      --multi-thread-cutoff SizeSuffix              Use multi-thread downloads for files above this size (default 256Mi)
      --multi-thread-streams int                    Number of streams to use for multi-thread downloads (default 4)
      --multi-thread-write-buffer-size SizeSuffix   In memory buffer size for writing when in multi-thread mode (default 128Ki)
      --no-check-dest                               Don't check the destination, copy regardless
      --no-traverse                                 Don't traverse destination file system on copy
      --no-update-modtime                           Don't update destination modtime if files identical
      --order-by string                             Instructions on how to order the transfers, e.g. 'size,descending'
      --partial-suffix string                       Add partial-suffix to temporary file name when --inplace is not used (default ".partial")
      --refresh-times                               Refresh the modtime of remote files
      --server-side-across-configs                  Allow server-side operations (e.g. copy) to work across different configs
      --size-only                                   Skip based on size only, not modtime or checksum
      --streaming-upload-cutoff SizeSuffix          Cutoff for switching to chunked upload if file size is unknown, upload starts after reaching cutoff or when file ends (default 100Ki)
  -u, --update                                      Skip files that are newer on the destination
```

2. sync同步相关参数

```
# Sync Flags

Flags just used for `rclone sync`.

      --backup-dir string               Make backups into hierarchy based in DIR
      --delete-after                    When synchronizing, delete files on destination after transferring (default)
      --delete-before                   When synchronizing, delete files on destination before transferring
      --delete-during                   When synchronizing, delete files during transfer
      --ignore-errors                   Delete even if there are I/O errors
      --max-delete int                  When synchronizing, limit the number of deletes (default -1)
      --max-delete-size SizeSuffix      When synchronizing, limit the total size of deletes (default off)
      --suffix string                   Suffix to add to changed files
      --suffix-keep-extension           Preserve the extension when using --suffix
      --track-renames                   When synchronizing, track file renames and do a server-side move if possible
      --track-renames-strategy string   Strategies to use when synchronizing using track-renames hash|modtime|leaf (default "hash")

# Important Flags

Important flags useful for most commands.

  -n, --dry-run         Do a trial run with no permanent changes
  -i, --interactive     Enable interactive mode
  -v, --verbose count   Print lots more stuff (repeat for more)

# Check Flags

Flags used for `rclone check`.

      --max-backlog int   Maximum number of objects in sync or check backlog (default 10000)

# Networking Flags

General networking and HTTP stuff.

      --bind string                        Local address to bind to for outgoing connections, IPv4, IPv6 or name
      --bwlimit BwTimetable                Bandwidth limit in KiB/s, or use suffix B|K|M|G|T|P or a full timetable
      --bwlimit-file BwTimetable           Bandwidth limit per file in KiB/s, or use suffix B|K|M|G|T|P or a full timetable
      --ca-cert stringArray                CA certificate used to verify servers
      --client-cert string                 Client SSL certificate (PEM) for mutual TLS auth
      --client-key string                  Client SSL private key (PEM) for mutual TLS auth
      --contimeout Duration                Connect timeout (default 1m0s)
      --disable-http-keep-alives           Disable HTTP keep-alives and use each connection once.
      --disable-http2                      Disable HTTP/2 in the global transport
      --dscp string                        Set DSCP value to connections, value or name, e.g. CS1, LE, DF, AF21
      --expect-continue-timeout Duration   Timeout when using expect / 100-continue in HTTP (default 1s)
      --header stringArray                 Set HTTP header for all transactions
      --header-download stringArray        Set HTTP header for download transactions
      --header-upload stringArray          Set HTTP header for upload transactions
      --no-check-certificate               Do not verify the server SSL certificate (insecure)
      --no-gzip-encoding                   Don't set Accept-Encoding: gzip
      --timeout Duration                   IO idle timeout (default 5m0s)
      --tpslimit float                     Limit HTTP transactions per second to this
      --tpslimit-burst int                 Max burst of transactions for --tpslimit (default 1)
      --use-cookies                        Enable session cookiejar
      --user-agent string                  Set the user-agent to a specified string (default "rclone/v1.65.1")

# Performance Flags

Flags helpful for increasing performance.

      --buffer-size SizeSuffix   In memory buffer size when reading files for each --transfer (default 16Mi)
      --checkers int             Number of checkers to run in parallel (default 8)
      --transfers int            Number of file transfers to run in parallel (default 4)
```

3. 配置相关参数

```
# Config Flags

General configuration of rclone.

      --ask-password                        Allow prompt for password for encrypted configuration (default true)
      --auto-confirm                        If enabled, do not request console confirmation
      --cache-dir string                    Directory rclone will use for caching (default "/root/.cache/rclone")
      --color AUTO|NEVER|ALWAYS             When to show colors (and other ANSI codes) AUTO|NEVER|ALWAYS (default AUTO)
      --config string                       Config file (default "/root/.config/rclone/rclone.conf")
      --default-time Time                   Time to show if modtime is unknown for files and directories (default 2000-01-01T00:00:00Z)
      --disable string                      Disable a comma separated list of features (use --disable help to see a list)
  -n, --dry-run                             Do a trial run with no permanent changes
      --error-on-no-transfer                Sets exit code 9 if no files are transferred, useful in scripts
      --fs-cache-expire-duration Duration   Cache remotes for this long (0 to disable caching) (default 5m0s)
      --fs-cache-expire-interval Duration   Interval to check for expired remotes (default 1m0s)
      --human-readable                      Print numbers in a human-readable format, sizes with suffix Ki|Mi|Gi|Ti|Pi
  -i, --interactive                         Enable interactive mode
      --kv-lock-time Duration               Maximum time to keep key-value database locked by process (default 1s)
      --low-level-retries int               Number of low level retries to do (default 10)
      --no-console                          Hide console window (supported on Windows only)
      --no-unicode-normalization            Don't normalize unicode characters in filenames
      --password-command SpaceSepList       Command for supplying password for encrypted configuration
      --retries int                         Retry operations this many times if they fail (default 3)
      --retries-sleep Duration              Interval between retrying operations if they fail, e.g. 500ms, 60s, 5m (0 to disable) (default 0s)
      --temp-dir string                     Directory rclone will use for temporary files (default "/tmp")
      --use-mmap                            Use mmap allocator (see docs)
      --use-server-modtime                  Use server modified time instead of object metadata

# Debugging Flags

Flags for developers.

      --cpuprofile string   Write cpu profile to file
      --dump DumpFlags      List of items to dump from: headers, bodies, requests, responses, auth, filters, goroutines, openfiles, mapper
      --dump-bodies         Dump HTTP headers and bodies - may contain sensitive info
      --dump-headers        Dump HTTP headers - may contain sensitive info
      --memprofile string   Write memory profile to file

# Filter Flags

Flags for filtering directory listings.

      --delete-excluded                     Delete files on dest excluded from sync
      --exclude stringArray                 Exclude files matching pattern
      --exclude-from stringArray            Read file exclude patterns from file (use - to read from stdin)
      --exclude-if-present stringArray      Exclude directories if filename is present
      --files-from stringArray              Read list of source-file names from file (use - to read from stdin)
      --files-from-raw stringArray          Read list of source-file names from file without any processing of lines (use - to read from stdin)
  -f, --filter stringArray                  Add a file filtering rule
      --filter-from stringArray             Read file filtering patterns from a file (use - to read from stdin)
      --ignore-case                         Ignore case in filters (case insensitive)
      --include stringArray                 Include files matching pattern
      --include-from stringArray            Read file include patterns from file (use - to read from stdin)
      --max-age Duration                    Only transfer files younger than this in s or suffix ms|s|m|h|d|w|M|y (default off)
      --max-depth int                       If set limits the recursion depth to this (default -1)
      --max-size SizeSuffix                 Only transfer files smaller than this in KiB or suffix B|K|M|G|T|P (default off)
      --metadata-exclude stringArray        Exclude metadatas matching pattern
      --metadata-exclude-from stringArray   Read metadata exclude patterns from file (use - to read from stdin)
      --metadata-filter stringArray         Add a metadata filtering rule
      --metadata-filter-from stringArray    Read metadata filtering patterns from a file (use - to read from stdin)
      --metadata-include stringArray        Include metadatas matching pattern
      --metadata-include-from stringArray   Read metadata include patterns from file (use - to read from stdin)
      --min-age Duration                    Only transfer files older than this in s or suffix ms|s|m|h|d|w|M|y (default off)
      --min-size SizeSuffix                 Only transfer files bigger than this in KiB or suffix B|K|M|G|T|P (default off)

# Listing Flags

Flags for listing directories.

      --default-time Time   Time to show if modtime is unknown for files and directories (default 2000-01-01T00:00:00Z)
      --fast-list           Use recursive list if available; uses more memory but fewer transactions

# Logging Flags

Logging and statistics.

      --log-file string                     Log everything to this file
      --log-format string                   Comma separated list of log format options (default "date,time")
      --log-level LogLevel                  Log level DEBUG|INFO|NOTICE|ERROR (default NOTICE)
      --log-systemd                         Activate systemd integration for the logger
      --max-stats-groups int                Maximum number of stats groups to keep in memory, on max oldest is discarded (default 1000)
  -P, --progress                            Show progress during transfer
      --progress-terminal-title             Show progress on the terminal title (requires -P/--progress)
  -q, --quiet                               Print as little stuff as possible
      --stats Duration                      Interval between printing stats, e.g. 500ms, 60s, 5m (0 to disable) (default 1m0s)
      --stats-file-name-length int          Max file name length in stats (0 for no limit) (default 45)
      --stats-log-level LogLevel            Log level to show --stats output DEBUG|INFO|NOTICE|ERROR (default INFO)
      --stats-one-line                      Make the stats fit on one line
      --stats-one-line-date                 Enable --stats-one-line and add current date/time prefix
      --stats-one-line-date-format string   Enable --stats-one-line-date and use custom formatted date: Enclose date string in double quotes ("), see https://golang.org/pkg/time/#Time.Format
      --stats-unit string                   Show data rate in stats as either 'bits' or 'bytes' per second (default "bytes")
      --syslog                              Use Syslog for logging
      --syslog-facility string              Facility for syslog, e.g. KERN,USER,... (default "DAEMON")
      --use-json-log                        Use json log format
  -v, --verbose count                       Print lots more stuff (repeat for more)

# Metadata Flags

Flags to control metadata.

  -M, --metadata                            If set, preserve metadata when copying objects
      --metadata-exclude stringArray        Exclude metadatas matching pattern
      --metadata-exclude-from stringArray   Read metadata exclude patterns from file (use - to read from stdin)
      --metadata-filter stringArray         Add a metadata filtering rule
      --metadata-filter-from stringArray    Read metadata filtering patterns from a file (use - to read from stdin)
      --metadata-include stringArray        Include metadatas matching pattern
      --metadata-include-from stringArray   Read metadata include patterns from file (use - to read from stdin)
      --metadata-mapper SpaceSepList        Program to run to transforming metadata before upload
      --metadata-set stringArray            Add metadata key=value when uploading

# RC Flags

Flags to control the Remote Control API.

      --rc                                 Enable the remote control server
      --rc-addr stringArray                IPaddress:Port or :Port to bind server to (default [localhost:5572])
      --rc-allow-origin string             Origin which cross-domain request (CORS) can be executed from
      --rc-baseurl string                  Prefix for URLs - leave blank for root
      --rc-cert string                     TLS PEM key (concatenation of certificate and CA certificate)
      --rc-client-ca string                Client certificate authority to verify clients with
      --rc-enable-metrics                  Enable prometheus metrics on /metrics
      --rc-files string                    Path to local files to serve on the HTTP server
      --rc-htpasswd string                 A htpasswd file - if not provided no authentication is done
      --rc-job-expire-duration Duration    Expire finished async jobs older than this value (default 1m0s)
      --rc-job-expire-interval Duration    Interval to check for expired async jobs (default 10s)
      --rc-key string                      TLS PEM Private key
      --rc-max-header-bytes int            Maximum size of request header (default 4096)
      --rc-min-tls-version string          Minimum TLS version that is acceptable (default "tls1.0")
      --rc-no-auth                         Don't require auth for certain methods
      --rc-pass string                     Password for authentication
      --rc-realm string                    Realm for authentication
      --rc-salt string                     Password hashing salt (default "dlPL2MqE")
      --rc-serve                           Enable the serving of remote objects
      --rc-server-read-timeout Duration    Timeout for server reading data (default 1h0m0s)
      --rc-server-write-timeout Duration   Timeout for server writing data (default 1h0m0s)
      --rc-template string                 User-specified template
      --rc-user string                     User name for authentication
      --rc-web-fetch-url string            URL to fetch the releases for webgui (default "https://api.github.com/repos/rclone/rclone-webui-react/releases/latest")
      --rc-web-gui                         Launch WebGUI on localhost
      --rc-web-gui-force-update            Force update to latest version of web gui
      --rc-web-gui-no-open-browser         Don't open the browser automatically
      --rc-web-gui-update                  Check and update to latest version of web gui
```

4. 后端参数

```
# Backend Flags

Backend only flags. These can be set in the config file also.

      --acd-auth-url string                                 Auth server URL
      --acd-client-id string                                OAuth Client Id
      --acd-client-secret string                            OAuth Client Secret
      --acd-encoding Encoding                               The encoding for the backend (default Slash,InvalidUtf8,Dot)
      --acd-templink-threshold SizeSuffix                   Files >= this size will be downloaded via their tempLink (default 9Gi)
      --acd-token string                                    OAuth Access Token as a JSON blob
      --acd-token-url string                                Token server url
      --acd-upload-wait-per-gb Duration                     Additional time per GiB to wait after a failed complete upload to see if it appears (default 3m0s)
      --alias-remote string                                 Remote or path to alias
      --azureblob-access-tier string                        Access tier of blob: hot, cool, cold or archive
      --azureblob-account string                            Azure Storage Account Name
      --azureblob-archive-tier-delete                       Delete archive tier blobs before overwriting
      --azureblob-chunk-size SizeSuffix                     Upload chunk size (default 4Mi)
      --azureblob-client-certificate-password string        Password for the certificate file (optional) (obscured)
      --azureblob-client-certificate-path string            Path to a PEM or PKCS12 certificate file including the private key
      --azureblob-client-id string                          The ID of the client in use
      --azureblob-client-secret string                      One of the service principal's client secrets
      --azureblob-client-send-certificate-chain             Send the certificate chain when using certificate auth
      --azureblob-directory-markers                         Upload an empty object with a trailing slash when a new directory is created
      --azureblob-disable-checksum                          Don't store MD5 checksum with object metadata
      --azureblob-encoding Encoding                         The encoding for the backend (default Slash,BackSlash,Del,Ctl,RightPeriod,InvalidUtf8)
      --azureblob-endpoint string                           Endpoint for the service
      --azureblob-env-auth                                  Read credentials from runtime (environment variables, CLI or MSI)
      --azureblob-key string                                Storage Account Shared Key
      --azureblob-list-chunk int                            Size of blob list (default 5000)
      --azureblob-msi-client-id string                      Object ID of the user-assigned MSI to use, if any
      --azureblob-msi-mi-res-id string                      Azure resource ID of the user-assigned MSI to use, if any
      --azureblob-msi-object-id string                      Object ID of the user-assigned MSI to use, if any
      --azureblob-no-check-container                        If set, don't attempt to check the container exists or create it
      --azureblob-no-head-object                            If set, do not do HEAD before GET when getting objects
      --azureblob-password string                           The user's password (obscured)
      --azureblob-public-access string                      Public access level of a container: blob or container
      --azureblob-sas-url string                            SAS URL for container level access only
      --azureblob-service-principal-file string             Path to file containing credentials for use with a service principal
      --azureblob-tenant string                             ID of the service principal's tenant. Also called its directory ID
      --azureblob-upload-concurrency int                    Concurrency for multipart uploads (default 16)
      --azureblob-upload-cutoff string                      Cutoff for switching to chunked upload (<= 256 MiB) (deprecated)
      --azureblob-use-emulator                              Uses local storage emulator if provided as 'true'
      --azureblob-use-msi                                   Use a managed service identity to authenticate (only works in Azure)
      --azureblob-username string                           User name (usually an email address)
      --azurefiles-account string                           Azure Storage Account Name
      --azurefiles-chunk-size SizeSuffix                    Upload chunk size (default 4Mi)
      --azurefiles-client-certificate-password string       Password for the certificate file (optional) (obscured)
      --azurefiles-client-certificate-path string           Path to a PEM or PKCS12 certificate file including the private key
      --azurefiles-client-id string                         The ID of the client in use
      --azurefiles-client-secret string                     One of the service principal's client secrets
      --azurefiles-client-send-certificate-chain            Send the certificate chain when using certificate auth
      --azurefiles-connection-string string                 Azure Files Connection String
      --azurefiles-encoding Encoding                        The encoding for the backend (default Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Del,Ctl,RightPeriod,InvalidUtf8,Dot)
      --azurefiles-endpoint string                          Endpoint for the service
      --azurefiles-env-auth                                 Read credentials from runtime (environment variables, CLI or MSI)
      --azurefiles-key string                               Storage Account Shared Key
      --azurefiles-max-stream-size SizeSuffix               Max size for streamed files (default 10Gi)
      --azurefiles-msi-client-id string                     Object ID of the user-assigned MSI to use, if any
      --azurefiles-msi-mi-res-id string                     Azure resource ID of the user-assigned MSI to use, if any
      --azurefiles-msi-object-id string                     Object ID of the user-assigned MSI to use, if any
      --azurefiles-password string                          The user's password (obscured)
      --azurefiles-sas-url string                           SAS URL
      --azurefiles-service-principal-file string            Path to file containing credentials for use with a service principal
      --azurefiles-share-name string                        Azure Files Share Name
      --azurefiles-tenant string                            ID of the service principal's tenant. Also called its directory ID
      --azurefiles-upload-concurrency int                   Concurrency for multipart uploads (default 16)
      --azurefiles-use-msi                                  Use a managed service identity to authenticate (only works in Azure)
      --azurefiles-username string                          User name (usually an email address)
      --b2-account string                                   Account ID or Application Key ID
      --b2-chunk-size SizeSuffix                            Upload chunk size (default 96Mi)
      --b2-copy-cutoff SizeSuffix                           Cutoff for switching to multipart copy (default 4Gi)
      --b2-disable-checksum                                 Disable checksums for large (> upload cutoff) files
      --b2-download-auth-duration Duration                  Time before the authorization token will expire in s or suffix ms|s|m|h|d (default 1w)
      --b2-download-url string                              Custom endpoint for downloads
      --b2-encoding Encoding                                The encoding for the backend (default Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot)
      --b2-endpoint string                                  Endpoint for the service
      --b2-hard-delete                                      Permanently delete files on remote removal, otherwise hide files
      --b2-key string                                       Application Key
      --b2-lifecycle int                                    Set the number of days deleted files should be kept when creating a bucket
      --b2-test-mode string                                 A flag string for X-Bz-Test-Mode header for debugging
      --b2-upload-concurrency int                           Concurrency for multipart uploads (default 4)
      --b2-upload-cutoff SizeSuffix                         Cutoff for switching to chunked upload (default 200Mi)
      --b2-version-at Time                                  Show file versions as they were at the specified time (default off)
      --b2-versions                                         Include old versions in directory listings
      --box-access-token string                             Box App Primary Access Token
      --box-auth-url string                                 Auth server URL
      --box-box-config-file string                          Box App config.json location
      --box-box-sub-type string                              (default "user")
      --box-client-id string                                OAuth Client Id
      --box-client-secret string                            OAuth Client Secret
      --box-commit-retries int                              Max number of times to try committing a multipart file (default 100)
      --box-encoding Encoding                               The encoding for the backend (default Slash,BackSlash,Del,Ctl,RightSpace,InvalidUtf8,Dot)
      --box-impersonate string                              Impersonate this user ID when using a service account
      --box-list-chunk int                                  Size of listing chunk 1-1000 (default 1000)
      --box-owned-by string                                 Only show items owned by the login (email address) passed in
      --box-root-folder-id string                           Fill in for rclone to use a non root folder as its starting point
      --box-token string                                    OAuth Access Token as a JSON blob
      --box-token-url string                                Token server url
      --box-upload-cutoff SizeSuffix                        Cutoff for switching to multipart upload (>= 50 MiB) (default 50Mi)
      --cache-chunk-clean-interval Duration                 How often should the cache perform cleanups of the chunk storage (default 1m0s)
      --cache-chunk-no-memory                               Disable the in-memory cache for storing chunks during streaming
      --cache-chunk-path string                             Directory to cache chunk files (default "/root/.cache/rclone/cache-backend")
      --cache-chunk-size SizeSuffix                         The size of a chunk (partial file data) (default 5Mi)
      --cache-chunk-total-size SizeSuffix                   The total size that the chunks can take up on the local disk (default 10Gi)
      --cache-db-path string                                Directory to store file structure metadata DB (default "/root/.cache/rclone/cache-backend")
      --cache-db-purge                                      Clear all the cached data for this remote on start
      --cache-db-wait-time Duration                         How long to wait for the DB to be available - 0 is unlimited (default 1s)
      --cache-info-age Duration                             How long to cache file structure information (directory listings, file size, times, etc.) (default 6h0m0s)
      --cache-plex-insecure string                          Skip all certificate verification when connecting to the Plex server
      --cache-plex-password string                          The password of the Plex user (obscured)
      --cache-plex-url string                               The URL of the Plex server
      --cache-plex-username string                          The username of the Plex user
      --cache-read-retries int                              How many times to retry a read from a cache storage (default 10)
      --cache-remote string                                 Remote to cache
      --cache-rps int                                       Limits the number of requests per second to the source FS (-1 to disable) (default -1)
      --cache-tmp-upload-path string                        Directory to keep temporary files until they are uploaded
      --cache-tmp-wait-time Duration                        How long should files be stored in local cache before being uploaded (default 15s)
      --cache-workers int                                   How many workers should run in parallel to download chunks (default 4)
      --cache-writes                                        Cache file data on writes through the FS
      --chunker-chunk-size SizeSuffix                       Files larger than chunk size will be split in chunks (default 2Gi)
      --chunker-fail-hard                                   Choose how chunker should handle files with missing or invalid chunks
      --chunker-hash-type string                            Choose how chunker handles hash sums (default "md5")
      --chunker-remote string                               Remote to chunk/unchunk
      --combine-upstreams SpaceSepList                      Upstreams for combining
      --compress-level int                                  GZIP compression level (-2 to 9) (default -1)
      --compress-mode string                                Compression mode (default "gzip")
      --compress-ram-cache-limit SizeSuffix                 Some remotes don't allow the upload of files with unknown size (default 20Mi)
      --compress-remote string                              Remote to compress
  -L, --copy-links                                          Follow symlinks and copy the pointed to item
      --crypt-directory-name-encryption                     Option to either encrypt directory names or leave them intact (default true)
      --crypt-filename-encoding string                      How to encode the encrypted filename to text string (default "base32")
      --crypt-filename-encryption string                    How to encrypt the filenames (default "standard")
      --crypt-no-data-encryption                            Option to either encrypt file data or leave it unencrypted
      --crypt-pass-bad-blocks                               If set this will pass bad blocks through as all 0
      --crypt-password string                               Password or pass phrase for encryption (obscured)
      --crypt-password2 string                              Password or pass phrase for salt (obscured)
      --crypt-remote string                                 Remote to encrypt/decrypt
      --crypt-server-side-across-configs                    Deprecated: use --server-side-across-configs instead
      --crypt-show-mapping                                  For all files listed show how the names encrypt
      --crypt-suffix string                                 If this is set it will override the default suffix of ".bin" (default ".bin")
      --drive-acknowledge-abuse                             Set to allow files which return cannotDownloadAbusiveFile to be downloaded
      --drive-allow-import-name-change                      Allow the filetype to change when uploading Google docs
      --drive-auth-owner-only                               Only consider files owned by the authenticated user
      --drive-auth-url string                               Auth server URL
      --drive-chunk-size SizeSuffix                         Upload chunk size (default 8Mi)
      --drive-client-id string                              Google Application Client Id
      --drive-client-secret string                          OAuth Client Secret
      --drive-copy-shortcut-content                         Server side copy contents of shortcuts instead of the shortcut
      --drive-disable-http2                                 Disable drive using http2 (default true)
      --drive-encoding Encoding                             The encoding for the backend (default InvalidUtf8)
      --drive-env-auth                                      Get IAM credentials from runtime (environment variables or instance meta data if no env vars)
      --drive-export-formats string                         Comma separated list of preferred formats for downloading Google docs (default "docx,xlsx,pptx,svg")
      --drive-fast-list-bug-fix                             Work around a bug in Google Drive listing (default true)
      --drive-formats string                                Deprecated: See export_formats
      --drive-impersonate string                            Impersonate this user when using a service account
      --drive-import-formats string                         Comma separated list of preferred formats for uploading Google docs
      --drive-keep-revision-forever                         Keep new head revision of each file forever
      --drive-list-chunk int                                Size of listing chunk 100-1000, 0 to disable (default 1000)
      --drive-metadata-labels Bits                          Control whether labels should be read or written in metadata (default off)
      --drive-metadata-owner Bits                           Control whether owner should be read or written in metadata (default read)
      --drive-metadata-permissions Bits                     Control whether permissions should be read or written in metadata (default off)
      --drive-pacer-burst int                               Number of API calls to allow without sleeping (default 100)
      --drive-pacer-min-sleep Duration                      Minimum time to sleep between API calls (default 100ms)
      --drive-resource-key string                           Resource key for accessing a link-shared file
      --drive-root-folder-id string                         ID of the root folder
      --drive-scope string                                  Comma separated list of scopes that rclone should use when requesting access from drive
      --drive-server-side-across-configs                    Deprecated: use --server-side-across-configs instead
      --drive-service-account-credentials string            Service Account Credentials JSON blob
      --drive-service-account-file string                   Service Account Credentials JSON file path
      --drive-shared-with-me                                Only show files that are shared with me
      --drive-show-all-gdocs                                Show all Google Docs including non-exportable ones in listings
      --drive-size-as-quota                                 Show sizes as storage quota usage, not actual size
      --drive-skip-checksum-gphotos                         Skip checksums on Google photos and videos only
      --drive-skip-dangling-shortcuts                       If set skip dangling shortcut files
      --drive-skip-gdocs                                    Skip google documents in all listings
      --drive-skip-shortcuts                                If set skip shortcut files
      --drive-starred-only                                  Only show files that are starred
      --drive-stop-on-download-limit                        Make download limit errors be fatal
      --drive-stop-on-upload-limit                          Make upload limit errors be fatal
      --drive-team-drive string                             ID of the Shared Drive (Team Drive)
      --drive-token string                                  OAuth Access Token as a JSON blob
      --drive-token-url string                              Token server url
      --drive-trashed-only                                  Only show files that are in the trash
      --drive-upload-cutoff SizeSuffix                      Cutoff for switching to chunked upload (default 8Mi)
      --drive-use-created-date                              Use file created date instead of modified date
      --drive-use-shared-date                               Use date file was shared instead of modified date
      --drive-use-trash                                     Send files to the trash instead of deleting permanently (default true)
      --drive-v2-download-min-size SizeSuffix               If Object's are greater, use drive v2 API to download (default off)
      --dropbox-auth-url string                             Auth server URL
      --dropbox-batch-commit-timeout Duration               Max time to wait for a batch to finish committing (default 10m0s)
      --dropbox-batch-mode string                           Upload file batching sync|async|off (default "sync")
      --dropbox-batch-size int                              Max number of files in upload batch
      --dropbox-batch-timeout Duration                      Max time to allow an idle upload batch before uploading (default 0s)
      --dropbox-chunk-size SizeSuffix                       Upload chunk size (< 150Mi) (default 48Mi)
      --dropbox-client-id string                            OAuth Client Id
      --dropbox-client-secret string                        OAuth Client Secret
      --dropbox-encoding Encoding                           The encoding for the backend (default Slash,BackSlash,Del,RightSpace,InvalidUtf8,Dot)
      --dropbox-impersonate string                          Impersonate this user when using a business account
      --dropbox-pacer-min-sleep Duration                    Minimum time to sleep between API calls (default 10ms)
      --dropbox-shared-files                                Instructs rclone to work on individual shared files
      --dropbox-shared-folders                              Instructs rclone to work on shared folders
      --dropbox-token string                                OAuth Access Token as a JSON blob
      --dropbox-token-url string                            Token server url
      --fichier-api-key string                              Your API Key, get it from https://1fichier.com/console/params.pl
      --fichier-cdn                                         Set if you wish to use CDN download links
      --fichier-encoding Encoding                           The encoding for the backend (default Slash,LtGt,DoubleQuote,SingleQuote,BackQuote,Dollar,BackSlash,Del,Ctl,LeftSpace,RightSpace,InvalidUtf8,Dot)
      --fichier-file-password string                        If you want to download a shared file that is password protected, add this parameter (obscured)
      --fichier-folder-password string                      If you want to list the files in a shared folder that is password protected, add this parameter (obscured)
      --fichier-shared-folder string                        If you want to download a shared folder, add this parameter
      --filefabric-encoding Encoding                        The encoding for the backend (default Slash,Del,Ctl,InvalidUtf8,Dot)
      --filefabric-permanent-token string                   Permanent Authentication Token
      --filefabric-root-folder-id string                    ID of the root folder
      --filefabric-token string                             Session Token
      --filefabric-token-expiry string                      Token expiry time
      --filefabric-url string                               URL of the Enterprise File Fabric to connect to
      --filefabric-version string                           Version read from the file fabric
      --ftp-ask-password                                    Allow asking for FTP password when needed
      --ftp-close-timeout Duration                          Maximum time to wait for a response to close (default 1m0s)
      --ftp-concurrency int                                 Maximum number of FTP simultaneous connections, 0 for unlimited
      --ftp-disable-epsv                                    Disable using EPSV even if server advertises support
      --ftp-disable-mlsd                                    Disable using MLSD even if server advertises support
      --ftp-disable-tls13                                   Disable TLS 1.3 (workaround for FTP servers with buggy TLS)
      --ftp-disable-utf8                                    Disable using UTF-8 even if server advertises support
      --ftp-encoding Encoding                               The encoding for the backend (default Slash,Del,Ctl,RightSpace,Dot)
      --ftp-explicit-tls                                    Use Explicit FTPS (FTP over TLS)
      --ftp-force-list-hidden                               Use LIST -a to force listing of hidden files and folders. This will disable the use of MLSD
      --ftp-host string                                     FTP host to connect to
      --ftp-idle-timeout Duration                           Max time before closing idle connections (default 1m0s)
      --ftp-no-check-certificate                            Do not verify the TLS certificate of the server
      --ftp-pass string                                     FTP password (obscured)
      --ftp-port int                                        FTP port number (default 21)
      --ftp-shut-timeout Duration                           Maximum time to wait for data connection closing status (default 1m0s)
      --ftp-socks-proxy string                              Socks 5 proxy host
      --ftp-tls                                             Use Implicit FTPS (FTP over TLS)
      --ftp-tls-cache-size int                              Size of TLS session cache for all control and data connections (default 32)
      --ftp-user string                                     FTP username (default "root")
      --ftp-writing-mdtm                                    Use MDTM to set modification time (VsFtpd quirk)
      --gcs-anonymous                                       Access public buckets and objects without credentials
      --gcs-auth-url string                                 Auth server URL
      --gcs-bucket-acl string                               Access Control List for new buckets
      --gcs-bucket-policy-only                              Access checks should use bucket-level IAM policies
      --gcs-client-id string                                OAuth Client Id
      --gcs-client-secret string                            OAuth Client Secret
      --gcs-decompress                                      If set this will decompress gzip encoded objects
      --gcs-directory-markers                               Upload an empty object with a trailing slash when a new directory is created
      --gcs-encoding Encoding                               The encoding for the backend (default Slash,CrLf,InvalidUtf8,Dot)
      --gcs-endpoint string                                 Endpoint for the service
      --gcs-env-auth                                        Get GCP IAM credentials from runtime (environment variables or instance meta data if no env vars)
      --gcs-location string                                 Location for the newly created buckets
      --gcs-no-check-bucket                                 If set, don't attempt to check the bucket exists or create it
      --gcs-object-acl string                               Access Control List for new objects
      --gcs-project-number string                           Project number
      --gcs-service-account-file string                     Service Account Credentials JSON file path
      --gcs-storage-class string                            The storage class to use when storing objects in Google Cloud Storage
      --gcs-token string                                    OAuth Access Token as a JSON blob
      --gcs-token-url string                                Token server url
      --gcs-user-project string                             User project
      --gphotos-auth-url string                             Auth server URL
      --gphotos-batch-commit-timeout Duration               Max time to wait for a batch to finish committing (default 10m0s)
      --gphotos-batch-mode string                           Upload file batching sync|async|off (default "sync")
      --gphotos-batch-size int                              Max number of files in upload batch
      --gphotos-batch-timeout Duration                      Max time to allow an idle upload batch before uploading (default 0s)
      --gphotos-client-id string                            OAuth Client Id
      --gphotos-client-secret string                        OAuth Client Secret
      --gphotos-encoding Encoding                           The encoding for the backend (default Slash,CrLf,InvalidUtf8,Dot)
      --gphotos-include-archived                            Also view and download archived media
      --gphotos-read-only                                   Set to make the Google Photos backend read only
      --gphotos-read-size                                   Set to read the size of media items
      --gphotos-start-year int                              Year limits the photos to be downloaded to those which are uploaded after the given year (default 2000)
      --gphotos-token string                                OAuth Access Token as a JSON blob
      --gphotos-token-url string                            Token server url
      --hasher-auto-size SizeSuffix                         Auto-update checksum for files smaller than this size (disabled by default)
      --hasher-hashes CommaSepList                          Comma separated list of supported checksum types (default md5,sha1)
      --hasher-max-age Duration                             Maximum time to keep checksums in cache (0 = no cache, off = cache forever) (default off)
      --hasher-remote string                                Remote to cache checksums for (e.g. myRemote:path)
      --hdfs-data-transfer-protection string                Kerberos data transfer protection: authentication|integrity|privacy
      --hdfs-encoding Encoding                              The encoding for the backend (default Slash,Colon,Del,Ctl,InvalidUtf8,Dot)
      --hdfs-namenode CommaSepList                          Hadoop name nodes and ports
      --hdfs-service-principal-name string                  Kerberos service principal name for the namenode
      --hdfs-username string                                Hadoop user name
      --hidrive-auth-url string                             Auth server URL
      --hidrive-chunk-size SizeSuffix                       Chunksize for chunked uploads (default 48Mi)
      --hidrive-client-id string                            OAuth Client Id
      --hidrive-client-secret string                        OAuth Client Secret
      --hidrive-disable-fetching-member-count               Do not fetch number of objects in directories unless it is absolutely necessary
      --hidrive-encoding Encoding                           The encoding for the backend (default Slash,Dot)
      --hidrive-endpoint string                             Endpoint for the service (default "https://api.hidrive.strato.com/2.1")
      --hidrive-root-prefix string                          The root/parent folder for all paths (default "/")
      --hidrive-scope-access string                         Access permissions that rclone should use when requesting access from HiDrive (default "rw")
      --hidrive-scope-role string                           User-level that rclone should use when requesting access from HiDrive (default "user")
      --hidrive-token string                                OAuth Access Token as a JSON blob
      --hidrive-token-url string                            Token server url
      --hidrive-upload-concurrency int                      Concurrency for chunked uploads (default 4)
      --hidrive-upload-cutoff SizeSuffix                    Cutoff/Threshold for chunked uploads (default 96Mi)
      --http-headers CommaSepList                           Set HTTP headers for all transactions
      --http-no-head                                        Don't use HEAD requests
      --http-no-slash                                       Set this if the site doesn't end directories with /
      --http-url string                                     URL of HTTP host to connect to
      --imagekit-encoding Encoding                          The encoding for the backend (default Slash,LtGt,DoubleQuote,Dollar,Question,Hash,Percent,BackSlash,Del,Ctl,InvalidUtf8,Dot,SquareBracket)
      --imagekit-endpoint string                            You can find your ImageKit.io URL endpoint in your [dashboard](https://imagekit.io/dashboard/developer/api-keys)
      --imagekit-only-signed Restrict unsigned image URLs   If you have configured Restrict unsigned image URLs in your dashboard settings, set this to true
      --imagekit-private-key string                         You can find your ImageKit.io private key in your [dashboard](https://imagekit.io/dashboard/developer/api-keys)
      --imagekit-public-key string                          You can find your ImageKit.io public key in your [dashboard](https://imagekit.io/dashboard/developer/api-keys)
      --imagekit-upload-tags string                         Tags to add to the uploaded files, e.g. "tag1,tag2"
      --imagekit-versions                                   Include old versions in directory listings
      --internetarchive-access-key-id string                IAS3 Access Key
      --internetarchive-disable-checksum                    Don't ask the server to test against MD5 checksum calculated by rclone (default true)
      --internetarchive-encoding Encoding                   The encoding for the backend (default Slash,LtGt,CrLf,Del,Ctl,InvalidUtf8,Dot)
      --internetarchive-endpoint string                     IAS3 Endpoint (default "https://s3.us.archive.org")
      --internetarchive-front-endpoint string               Host of InternetArchive Frontend (default "https://archive.org")
      --internetarchive-secret-access-key string            IAS3 Secret Key (password)
      --internetarchive-wait-archive Duration               Timeout for waiting the server's processing tasks (specifically archive and book_op) to finish (default 0s)
      --jottacloud-auth-url string                          Auth server URL
      --jottacloud-client-id string                         OAuth Client Id
      --jottacloud-client-secret string                     OAuth Client Secret
      --jottacloud-encoding Encoding                        The encoding for the backend (default Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,Del,Ctl,InvalidUtf8,Dot)
      --jottacloud-hard-delete                              Delete files permanently rather than putting them into the trash
      --jottacloud-md5-memory-limit SizeSuffix              Files bigger than this will be cached on disk to calculate the MD5 if required (default 10Mi)
      --jottacloud-no-versions                              Avoid server side versioning by deleting files and recreating files instead of overwriting them
      --jottacloud-token string                             OAuth Access Token as a JSON blob
      --jottacloud-token-url string                         Token server url
      --jottacloud-trashed-only                             Only show files that are in the trash
      --jottacloud-upload-resume-limit SizeSuffix           Files bigger than this can be resumed if the upload fail's (default 10Mi)
      --koofr-encoding Encoding                             The encoding for the backend (default Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot)
      --koofr-endpoint string                               The Koofr API endpoint to use
      --koofr-mountid string                                Mount ID of the mount to use
      --koofr-password string                               Your password for rclone (generate one at https://app.koofr.net/app/admin/preferences/password) (obscured)
      --koofr-provider string                               Choose your storage provider
      --koofr-setmtime                                      Does the backend support setting modification time (default true)
      --koofr-user string                                   Your user name
      --linkbox-token string                                Token from https://www.linkbox.to/admin/account
  -l, --links                                               Translate symlinks to/from regular files with a '.rclonelink' extension
      --local-case-insensitive                              Force the filesystem to report itself as case insensitive
      --local-case-sensitive                                Force the filesystem to report itself as case sensitive
      --local-encoding Encoding                             The encoding for the backend (default Slash,Dot)
      --local-no-check-updated                              Don't check to see if the files change during upload
      --local-no-preallocate                                Disable preallocation of disk space for transferred files
      --local-no-set-modtime                                Disable setting modtime
      --local-no-sparse                                     Disable sparse files for multi-thread downloads
      --local-nounc                                         Disable UNC (long path names) conversion on Windows
      --local-unicode-normalization                         Apply unicode NFC normalization to paths and filenames
      --local-zero-size-links                               Assume the Stat size of links is zero (and read them instead) (deprecated)
      --mailru-auth-url string                              Auth server URL
      --mailru-check-hash                                   What should copy do if file checksum is mismatched or invalid (default true)
      --mailru-client-id string                             OAuth Client Id
      --mailru-client-secret string                         OAuth Client Secret
      --mailru-encoding Encoding                            The encoding for the backend (default Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Del,Ctl,InvalidUtf8,Dot)
      --mailru-pass string                                  Password (obscured)
      --mailru-speedup-enable                               Skip full upload if there is another file with same data hash (default true)
      --mailru-speedup-file-patterns string                 Comma separated list of file name patterns eligible for speedup (put by hash) (default "*.mkv,*.avi,*.mp4,*.mp3,*.zip,*.gz,*.rar,*.pdf")
      --mailru-speedup-max-disk SizeSuffix                  This option allows you to disable speedup (put by hash) for large files (default 3Gi)
      --mailru-speedup-max-memory SizeSuffix                Files larger than the size given below will always be hashed on disk (default 32Mi)
      --mailru-token string                                 OAuth Access Token as a JSON blob
      --mailru-token-url string                             Token server url
      --mailru-user string                                  User name (usually email)
      --mega-debug                                          Output more debug from Mega
      --mega-encoding Encoding                              The encoding for the backend (default Slash,InvalidUtf8,Dot)
      --mega-hard-delete                                    Delete files permanently rather than putting them into the trash
      --mega-pass string                                    Password (obscured)
      --mega-use-https                                      Use HTTPS for transfers
      --mega-user string                                    User name
      --netstorage-account string                           Set the NetStorage account name
      --netstorage-host string                              Domain+path of NetStorage host to connect to
      --netstorage-protocol string                          Select between HTTP or HTTPS protocol (default "https")
      --netstorage-secret string                            Set the NetStorage account secret/G2O key for authentication (obscured)
  -x, --one-file-system                                     Don't cross filesystem boundaries (unix/macOS only)
      --onedrive-access-scopes SpaceSepList                 Set scopes to be requested by rclone (default Files.Read Files.ReadWrite Files.Read.All Files.ReadWrite.All Sites.Read.All offline_access)
      --onedrive-auth-url string                            Auth server URL
      --onedrive-av-override                                Allows download of files the server thinks has a virus
      --onedrive-chunk-size SizeSuffix                      Chunk size to upload files with - must be multiple of 320k (327,680 bytes) (default 10Mi)
      --onedrive-client-id string                           OAuth Client Id
      --onedrive-client-secret string                       OAuth Client Secret
      --onedrive-delta                                      If set rclone will use delta listing to implement recursive listings
      --onedrive-drive-id string                            The ID of the drive to use
      --onedrive-drive-type string                          The type of the drive (personal | business | documentLibrary)
      --onedrive-encoding Encoding                          The encoding for the backend (default Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Del,Ctl,LeftSpace,LeftTilde,RightSpace,RightPeriod,InvalidUtf8,Dot)
      --onedrive-expose-onenote-files                       Set to make OneNote files show up in directory listings
      --onedrive-hash-type string                           Specify the hash in use for the backend (default "auto")
      --onedrive-link-password string                       Set the password for links created by the link command
      --onedrive-link-scope string                          Set the scope of the links created by the link command (default "anonymous")
      --onedrive-link-type string                           Set the type of the links created by the link command (default "view")
      --onedrive-list-chunk int                             Size of listing chunk (default 1000)
      --onedrive-no-versions                                Remove all versions on modifying operations
      --onedrive-region string                              Choose national cloud region for OneDrive (default "global")
      --onedrive-root-folder-id string                      ID of the root folder
      --onedrive-server-side-across-configs                 Deprecated: use --server-side-across-configs instead
      --onedrive-token string                               OAuth Access Token as a JSON blob
      --onedrive-token-url string                           Token server url
      --oos-attempt-resume-upload                           If true attempt to resume previously started multipart upload for the object
      --oos-chunk-size SizeSuffix                           Chunk size to use for uploading (default 5Mi)
      --oos-compartment string                              Object storage compartment OCID
      --oos-config-file string                              Path to OCI config file (default "~/.oci/config")
      --oos-config-profile string                           Profile name inside the oci config file (default "Default")
      --oos-copy-cutoff SizeSuffix                          Cutoff for switching to multipart copy (default 4.656Gi)
      --oos-copy-timeout Duration                           Timeout for copy (default 1m0s)
      --oos-disable-checksum                                Don't store MD5 checksum with object metadata
      --oos-encoding Encoding                               The encoding for the backend (default Slash,InvalidUtf8,Dot)
      --oos-endpoint string                                 Endpoint for Object storage API
      --oos-leave-parts-on-error                            If true avoid calling abort upload on a failure, leaving all successfully uploaded parts for manual recovery
      --oos-max-upload-parts int                            Maximum number of parts in a multipart upload (default 10000)
      --oos-namespace string                                Object storage namespace
      --oos-no-check-bucket                                 If set, don't attempt to check the bucket exists or create it
      --oos-provider string                                 Choose your Auth Provider (default "env_auth")
      --oos-region string                                   Object storage Region
      --oos-sse-customer-algorithm string                   If using SSE-C, the optional header that specifies "AES256" as the encryption algorithm
      --oos-sse-customer-key string                         To use SSE-C, the optional header that specifies the base64-encoded 256-bit encryption key to use to
      --oos-sse-customer-key-file string                    To use SSE-C, a file containing the base64-encoded string of the AES-256 encryption key associated
      --oos-sse-customer-key-sha256 string                  If using SSE-C, The optional header that specifies the base64-encoded SHA256 hash of the encryption
      --oos-sse-kms-key-id string                           if using your own master key in vault, this header specifies the
      --oos-storage-tier string                             The storage class to use when storing new objects in storage. https://docs.oracle.com/en-us/iaas/Content/Object/Concepts/understandingstoragetiers.htm (default "Standard")
      --oos-upload-concurrency int                          Concurrency for multipart uploads (default 10)
      --oos-upload-cutoff SizeSuffix                        Cutoff for switching to chunked upload (default 200Mi)
      --opendrive-chunk-size SizeSuffix                     Files will be uploaded in chunks this size (default 10Mi)
      --opendrive-encoding Encoding                         The encoding for the backend (default Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,LeftSpace,LeftCrLfHtVt,RightSpace,RightCrLfHtVt,InvalidUtf8,Dot)
      --opendrive-password string                           Password (obscured)
      --opendrive-username string                           Username
      --pcloud-auth-url string                              Auth server URL
      --pcloud-client-id string                             OAuth Client Id
      --pcloud-client-secret string                         OAuth Client Secret
      --pcloud-encoding Encoding                            The encoding for the backend (default Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot)
      --pcloud-hostname string                              Hostname to connect to (default "api.pcloud.com")
      --pcloud-password string                              Your pcloud password (obscured)
      --pcloud-root-folder-id string                        Fill in for rclone to use a non root folder as its starting point (default "d0")
      --pcloud-token string                                 OAuth Access Token as a JSON blob
      --pcloud-token-url string                             Token server url
      --pcloud-username string                              Your pcloud username
      --pikpak-auth-url string                              Auth server URL
      --pikpak-client-id string                             OAuth Client Id
      --pikpak-client-secret string                         OAuth Client Secret
      --pikpak-encoding Encoding                            The encoding for the backend (default Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Ctl,LeftSpace,RightSpace,RightPeriod,InvalidUtf8,Dot)
      --pikpak-hash-memory-limit SizeSuffix                 Files bigger than this will be cached on disk to calculate hash if required (default 10Mi)
      --pikpak-pass string                                  Pikpak password (obscured)
      --pikpak-root-folder-id string                        ID of the root folder
      --pikpak-token string                                 OAuth Access Token as a JSON blob
      --pikpak-token-url string                             Token server url
      --pikpak-trashed-only                                 Only show files that are in the trash
      --pikpak-use-trash                                    Send files to the trash instead of deleting permanently (default true)
      --pikpak-user string                                  Pikpak username
      --premiumizeme-auth-url string                        Auth server URL
      --premiumizeme-client-id string                       OAuth Client Id
      --premiumizeme-client-secret string                   OAuth Client Secret
      --premiumizeme-encoding Encoding                      The encoding for the backend (default Slash,DoubleQuote,BackSlash,Del,Ctl,InvalidUtf8,Dot)
      --premiumizeme-token string                           OAuth Access Token as a JSON blob
      --premiumizeme-token-url string                       Token server url
      --protondrive-2fa string                              The 2FA code
      --protondrive-app-version string                      The app version string (default "macos-drive@1.0.0-alpha.1+rclone")
      --protondrive-enable-caching                          Caches the files and folders metadata to reduce API calls (default true)
      --protondrive-encoding Encoding                       The encoding for the backend (default Slash,LeftSpace,RightSpace,InvalidUtf8,Dot)
      --protondrive-mailbox-password string                 The mailbox password of your two-password proton account (obscured)
      --protondrive-original-file-size                      Return the file size before encryption (default true)
      --protondrive-password string                         The password of your proton account (obscured)
      --protondrive-replace-existing-draft                  Create a new revision when filename conflict is detected
      --protondrive-username string                         The username of your proton account
      --putio-auth-url string                               Auth server URL
      --putio-client-id string                              OAuth Client Id
      --putio-client-secret string                          OAuth Client Secret
      --putio-encoding Encoding                             The encoding for the backend (default Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot)
      --putio-token string                                  OAuth Access Token as a JSON blob
      --putio-token-url string                              Token server url
      --qingstor-access-key-id string                       QingStor Access Key ID
      --qingstor-chunk-size SizeSuffix                      Chunk size to use for uploading (default 4Mi)
      --qingstor-connection-retries int                     Number of connection retries (default 3)
      --qingstor-encoding Encoding                          The encoding for the backend (default Slash,Ctl,InvalidUtf8)
      --qingstor-endpoint string                            Enter an endpoint URL to connection QingStor API
      --qingstor-env-auth                                   Get QingStor credentials from runtime
      --qingstor-secret-access-key string                   QingStor Secret Access Key (password)
      --qingstor-upload-concurrency int                     Concurrency for multipart uploads (default 1)
      --qingstor-upload-cutoff SizeSuffix                   Cutoff for switching to chunked upload (default 200Mi)
      --qingstor-zone string                                Zone to connect to
      --quatrix-api-key string                              API key for accessing Quatrix account
      --quatrix-effective-upload-time string                Wanted upload time for one chunk (default "4s")
      --quatrix-encoding Encoding                           The encoding for the backend (default Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot)
      --quatrix-hard-delete                                 Delete files permanently rather than putting them into the trash
      --quatrix-host string                                 Host name of Quatrix account
      --quatrix-maximal-summary-chunk-size SizeSuffix       The maximal summary for all chunks. It should not be less than 'transfers'*'minimal_chunk_size' (default 95.367Mi)
      --quatrix-minimal-chunk-size SizeSuffix               The minimal size for one chunk (default 9.537Mi)
      --s3-access-key-id string                             AWS Access Key ID
      --s3-acl string                                       Canned ACL used when creating buckets and storing or copying objects
      --s3-bucket-acl string                                Canned ACL used when creating buckets
      --s3-chunk-size SizeSuffix                            Chunk size to use for uploading (default 5Mi)
      --s3-copy-cutoff SizeSuffix                           Cutoff for switching to multipart copy (default 4.656Gi)
      --s3-decompress                                       If set this will decompress gzip encoded objects
      --s3-directory-markers                                Upload an empty object with a trailing slash when a new directory is created
      --s3-disable-checksum                                 Don't store MD5 checksum with object metadata
      --s3-disable-http2                                    Disable usage of http2 for S3 backends
      --s3-download-url string                              Custom endpoint for downloads
      --s3-encoding Encoding                                The encoding for the backend (default Slash,InvalidUtf8,Dot)
      --s3-endpoint string                                  Endpoint for S3 API
      --s3-env-auth                                         Get AWS credentials from runtime (environment variables or EC2/ECS meta data if no env vars)
      --s3-force-path-style                                 If true use path style access if false use virtual hosted style (default true)
      --s3-leave-parts-on-error                             If true avoid calling abort upload on a failure, leaving all successfully uploaded parts on S3 for manual recovery
      --s3-list-chunk int                                   Size of listing chunk (response list for each ListObject S3 request) (default 1000)
      --s3-list-url-encode Tristate                         Whether to url encode listings: true/false/unset (default unset)
      --s3-list-version int                                 Version of ListObjects to use: 1,2 or 0 for auto
      --s3-location-constraint string                       Location constraint - must be set to match the Region
      --s3-max-upload-parts int                             Maximum number of parts in a multipart upload (default 10000)
      --s3-might-gzip Tristate                              Set this if the backend might gzip objects (default unset)
      --s3-no-check-bucket                                  If set, don't attempt to check the bucket exists or create it
      --s3-no-head                                          If set, don't HEAD uploaded objects to check integrity
      --s3-no-head-object                                   If set, do not do HEAD before GET when getting objects
      --s3-no-system-metadata                               Suppress setting and reading of system metadata
      --s3-profile string                                   Profile to use in the shared credentials file
      --s3-provider string                                  Choose your S3 provider
      --s3-region string                                    Region to connect to
      --s3-requester-pays                                   Enables requester pays option when interacting with S3 bucket
      --s3-secret-access-key string                         AWS Secret Access Key (password)
      --s3-server-side-encryption string                    The server-side encryption algorithm used when storing this object in S3
      --s3-session-token string                             An AWS session token
      --s3-shared-credentials-file string                   Path to the shared credentials file
      --s3-sse-customer-algorithm string                    If using SSE-C, the server-side encryption algorithm used when storing this object in S3
      --s3-sse-customer-key string                          To use SSE-C you may provide the secret encryption key used to encrypt/decrypt your data
      --s3-sse-customer-key-base64 string                   If using SSE-C you must provide the secret encryption key encoded in base64 format to encrypt/decrypt your data
      --s3-sse-customer-key-md5 string                      If using SSE-C you may provide the secret encryption key MD5 checksum (optional)
      --s3-sse-kms-key-id string                            If using KMS ID you must provide the ARN of Key
      --s3-storage-class string                             The storage class to use when storing new objects in S3
      --s3-sts-endpoint string                              Endpoint for STS
      --s3-upload-concurrency int                           Concurrency for multipart uploads (default 4)
      --s3-upload-cutoff SizeSuffix                         Cutoff for switching to chunked upload (default 200Mi)
      --s3-use-accelerate-endpoint                          If true use the AWS S3 accelerated endpoint
      --s3-use-accept-encoding-gzip Accept-Encoding: gzip   Whether to send Accept-Encoding: gzip header (default unset)
      --s3-use-already-exists Tristate                      Set if rclone should report BucketAlreadyExists errors on bucket creation (default unset)
      --s3-use-multipart-etag Tristate                      Whether to use ETag in multipart uploads for verification (default unset)
      --s3-use-multipart-uploads Tristate                   Set if rclone should use multipart uploads (default unset)
      --s3-use-presigned-request                            Whether to use a presigned request or PutObject for single part uploads
      --s3-v2-auth                                          If true use v2 authentication
      --s3-version-at Time                                  Show file versions as they were at the specified time (default off)
      --s3-versions                                         Include old versions in directory listings
      --seafile-2fa                                         Two-factor authentication ('true' if the account has 2FA enabled)
      --seafile-create-library                              Should rclone create a library if it doesn't exist
      --seafile-encoding Encoding                           The encoding for the backend (default Slash,DoubleQuote,BackSlash,Ctl,InvalidUtf8)
      --seafile-library string                              Name of the library
      --seafile-library-key string                          Library password (for encrypted libraries only) (obscured)
      --seafile-pass string                                 Password (obscured)
      --seafile-url string                                  URL of seafile host to connect to
      --seafile-user string                                 User name (usually email address)
      --sftp-ask-password                                   Allow asking for SFTP password when needed
      --sftp-chunk-size SizeSuffix                          Upload and download chunk size (default 32Ki)
      --sftp-ciphers SpaceSepList                           Space separated list of ciphers to be used for session encryption, ordered by preference
      --sftp-concurrency int                                The maximum number of outstanding requests for one file (default 64)
      --sftp-copy-is-hardlink                               Set to enable server side copies using hardlinks
      --sftp-disable-concurrent-reads                       If set don't use concurrent reads
      --sftp-disable-concurrent-writes                      If set don't use concurrent writes
      --sftp-disable-hashcheck                              Disable the execution of SSH commands to determine if remote file hashing is available
      --sftp-host string                                    SSH host to connect to
      --sftp-host-key-algorithms SpaceSepList               Space separated list of host key algorithms, ordered by preference
      --sftp-idle-timeout Duration                          Max time before closing idle connections (default 1m0s)
      --sftp-key-exchange SpaceSepList                      Space separated list of key exchange algorithms, ordered by preference
      --sftp-key-file string                                Path to PEM-encoded private key file
      --sftp-key-file-pass string                           The passphrase to decrypt the PEM-encoded private key file (obscured)
      --sftp-key-pem string                                 Raw PEM-encoded private key
      --sftp-key-use-agent                                  When set forces the usage of the ssh-agent
      --sftp-known-hosts-file string                        Optional path to known_hosts file
      --sftp-macs SpaceSepList                              Space separated list of MACs (message authentication code) algorithms, ordered by preference
      --sftp-md5sum-command string                          The command used to read md5 hashes
      --sftp-pass string                                    SSH password, leave blank to use ssh-agent (obscured)
      --sftp-path-override string                           Override path used by SSH shell commands
      --sftp-port int                                       SSH port number (default 22)
      --sftp-pubkey-file string                             Optional path to public key file
      --sftp-server-command string                          Specifies the path or command to run a sftp server on the remote host
      --sftp-set-env SpaceSepList                           Environment variables to pass to sftp and commands
      --sftp-set-modtime                                    Set the modified time on the remote if set (default true)
      --sftp-sha1sum-command string                         The command used to read sha1 hashes
      --sftp-shell-type string                              The type of SSH shell on remote server, if any
      --sftp-skip-links                                     Set to skip any symlinks and any other non regular files
      --sftp-socks-proxy string                             Socks 5 proxy host
      --sftp-ssh SpaceSepList                               Path and arguments to external ssh binary
      --sftp-subsystem string                               Specifies the SSH2 subsystem on the remote host (default "sftp")
      --sftp-use-fstat                                      If set use fstat instead of stat
      --sftp-use-insecure-cipher                            Enable the use of insecure ciphers and key exchange methods
      --sftp-user string                                    SSH username (default "root")
      --sharefile-auth-url string                           Auth server URL
      --sharefile-chunk-size SizeSuffix                     Upload chunk size (default 64Mi)
      --sharefile-client-id string                          OAuth Client Id
      --sharefile-client-secret string                      OAuth Client Secret
      --sharefile-encoding Encoding                         The encoding for the backend (default Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Ctl,LeftSpace,LeftPeriod,RightSpace,RightPeriod,InvalidUtf8,Dot)
      --sharefile-endpoint string                           Endpoint for API calls
      --sharefile-root-folder-id string                     ID of the root folder
      --sharefile-token string                              OAuth Access Token as a JSON blob
      --sharefile-token-url string                          Token server url
      --sharefile-upload-cutoff SizeSuffix                  Cutoff for switching to multipart upload (default 128Mi)
      --sia-api-password string                             Sia Daemon API Password (obscured)
      --sia-api-url string                                  Sia daemon API URL, like http://sia.daemon.host:9980 (default "http://127.0.0.1:9980")
      --sia-encoding Encoding                               The encoding for the backend (default Slash,Question,Hash,Percent,Del,Ctl,InvalidUtf8,Dot)
      --sia-user-agent string                               Siad User Agent (default "Sia-Agent")
      --skip-links                                          Don't warn about skipped symlinks
      --smb-case-insensitive                                Whether the server is configured to be case-insensitive (default true)
      --smb-domain string                                   Domain name for NTLM authentication (default "WORKGROUP")
      --smb-encoding Encoding                               The encoding for the backend (default Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Ctl,RightSpace,RightPeriod,InvalidUtf8,Dot)
      --smb-hide-special-share                              Hide special shares (e.g. print$) which users aren't supposed to access (default true)
      --smb-host string                                     SMB server hostname to connect to
      --smb-idle-timeout Duration                           Max time before closing idle connections (default 1m0s)
      --smb-pass string                                     SMB password (obscured)
      --smb-port int                                        SMB port number (default 445)
      --smb-spn string                                      Service principal name
      --smb-user string                                     SMB username (default "root")
      --storj-access-grant string                           Access grant
      --storj-api-key string                                API key
      --storj-passphrase string                             Encryption passphrase
      --storj-provider string                               Choose an authentication method (default "existing")
      --storj-satellite-address string                      Satellite address (default "us1.storj.io")
      --sugarsync-access-key-id string                      Sugarsync Access Key ID
      --sugarsync-app-id string                             Sugarsync App ID
      --sugarsync-authorization string                      Sugarsync authorization
      --sugarsync-authorization-expiry string               Sugarsync authorization expiry
      --sugarsync-deleted-id string                         Sugarsync deleted folder id
      --sugarsync-encoding Encoding                         The encoding for the backend (default Slash,Ctl,InvalidUtf8,Dot)
      --sugarsync-hard-delete                               Permanently delete files if true
      --sugarsync-private-access-key string                 Sugarsync Private Access Key
      --sugarsync-refresh-token string                      Sugarsync refresh token
      --sugarsync-root-id string                            Sugarsync root id
      --sugarsync-user string                               Sugarsync user
      --swift-application-credential-id string              Application Credential ID (OS_APPLICATION_CREDENTIAL_ID)
      --swift-application-credential-name string            Application Credential Name (OS_APPLICATION_CREDENTIAL_NAME)
      --swift-application-credential-secret string          Application Credential Secret (OS_APPLICATION_CREDENTIAL_SECRET)
      --swift-auth string                                   Authentication URL for server (OS_AUTH_URL)
      --swift-auth-token string                             Auth Token from alternate authentication - optional (OS_AUTH_TOKEN)
      --swift-auth-version int                              AuthVersion - optional - set to (1,2,3) if your auth URL has no version (ST_AUTH_VERSION)
      --swift-chunk-size SizeSuffix                         Above this size files will be chunked into a _segments container (default 5Gi)
      --swift-domain string                                 User domain - optional (v3 auth) (OS_USER_DOMAIN_NAME)
      --swift-encoding Encoding                             The encoding for the backend (default Slash,InvalidUtf8)
      --swift-endpoint-type string                          Endpoint type to choose from the service catalogue (OS_ENDPOINT_TYPE) (default "public")
      --swift-env-auth                                      Get swift credentials from environment variables in standard OpenStack form
      --swift-key string                                    API key or password (OS_PASSWORD)
      --swift-leave-parts-on-error                          If true avoid calling abort upload on a failure
      --swift-no-chunk                                      Don't chunk files during streaming upload
      --swift-no-large-objects                              Disable support for static and dynamic large objects
      --swift-region string                                 Region name - optional (OS_REGION_NAME)
      --swift-storage-policy string                         The storage policy to use when creating a new container
      --swift-storage-url string                            Storage URL - optional (OS_STORAGE_URL)
      --swift-tenant string                                 Tenant name - optional for v1 auth, this or tenant_id required otherwise (OS_TENANT_NAME or OS_PROJECT_NAME)
      --swift-tenant-domain string                          Tenant domain - optional (v3 auth) (OS_PROJECT_DOMAIN_NAME)
      --swift-tenant-id string                              Tenant ID - optional for v1 auth, this or tenant required otherwise (OS_TENANT_ID)
      --swift-user string                                   User name to log in (OS_USERNAME)
      --swift-user-id string                                User ID to log in - optional - most swift systems use user and leave this blank (v3 auth) (OS_USER_ID)
      --union-action-policy string                          Policy to choose upstream on ACTION category (default "epall")
      --union-cache-time int                                Cache time of usage and free space (in seconds) (default 120)
      --union-create-policy string                          Policy to choose upstream on CREATE category (default "epmfs")
      --union-min-free-space SizeSuffix                     Minimum viable free space for lfs/eplfs policies (default 1Gi)
      --union-search-policy string                          Policy to choose upstream on SEARCH category (default "ff")
      --union-upstreams string                              List of space separated upstreams
      --uptobox-access-token string                         Your access token
      --uptobox-encoding Encoding                           The encoding for the backend (default Slash,LtGt,DoubleQuote,BackQuote,Del,Ctl,LeftSpace,InvalidUtf8,Dot)
      --uptobox-private                                     Set to make uploaded files private
      --webdav-bearer-token string                          Bearer token instead of user/pass (e.g. a Macaroon)
      --webdav-bearer-token-command string                  Command to run to get a bearer token
      --webdav-encoding string                              The encoding for the backend
      --webdav-headers CommaSepList                         Set HTTP headers for all transactions
      --webdav-nextcloud-chunk-size SizeSuffix              Nextcloud upload chunk size (default 10Mi)
      --webdav-pacer-min-sleep Duration                     Minimum time to sleep between API calls (default 10ms)
      --webdav-pass string                                  Password (obscured)
      --webdav-url string                                   URL of http host to connect to
      --webdav-user string                                  User name
      --webdav-vendor string                                Name of the WebDAV site/service/software you are using
      --yandex-auth-url string                              Auth server URL
      --yandex-client-id string                             OAuth Client Id
      --yandex-client-secret string                         OAuth Client Secret
      --yandex-encoding Encoding                            The encoding for the backend (default Slash,Del,Ctl,InvalidUtf8,Dot)
      --yandex-hard-delete                                  Delete files permanently rather than putting them into the trash
      --yandex-token string                                 OAuth Access Token as a JSON blob
      --yandex-token-url string                             Token server url
      --zoho-auth-url string                                Auth server URL
      --zoho-client-id string                               OAuth Client Id
      --zoho-client-secret string                           OAuth Client Secret
      --zoho-encoding Encoding                              The encoding for the backend (default Del,Ctl,InvalidUtf8)
      --zoho-region string                                  Zoho region to connect to
      --zoho-token string                                   OAuth Access Token as a JSON blob
      --zoho-token-url string                               Token server url


Additional help topics:

Use "rclone [command] --help" for more information about a command.
Use "rclone help flags" for to see the global flags.
Use "rclone help backends" for a list of supported services.
```


### 参考资料

- Rclone 进阶使用教程 - 自建私有 API 挂载 OneDrive ：https://p3terx.com/archives/rclone-connect-onedrive-with-selfbuilt-api.html
- [rclone配置onedrive和google drive上传教程](https://hechuan.me/rclone/)



